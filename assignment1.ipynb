{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question 1 - display all the header tags from \n",
    "‘en.wikipedia.org/wiki/Main_Page’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h1 Main Page',\n",
       " 'h1 Welcome to Wikipedia',\n",
       " \"h2 From today's featured article\",\n",
       " 'h2 Did you know\\xa0...',\n",
       " 'h2 In the news',\n",
       " 'h2 On this day',\n",
       " \"h2 Today's featured picture\",\n",
       " 'h2 Other areas of Wikipedia',\n",
       " \"h2 Wikipedia's sister projects\",\n",
       " 'h2 Wikipedia languages']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "page = requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "\n",
    "# page content\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "header_tags = [] # empty list\n",
    "for header in soup.find_all([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\",\"h6\"]):\n",
    "    header_tags.append(header.name+\" \"+header.text.strip())\n",
    "    \n",
    "# print all header_tags\n",
    "header_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2 - Write s python program to display list of respected former presidents of India(i.e. Name , Term of office) \n",
    "from https://presidentofindia.nic.in/former-presidents.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind</td>\n",
       "      <td>14th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "      <td>13th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "      <td>12th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "      <td>11th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "      <td>10th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma</td>\n",
       "      <td>9th  President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman</td>\n",
       "      <td>8th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh</td>\n",
       "      <td>7th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy</td>\n",
       "      <td>6th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed</td>\n",
       "      <td>5th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri</td>\n",
       "      <td>4th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain</td>\n",
       "      <td>3rd President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan</td>\n",
       "      <td>2nd President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad</td>\n",
       "      <td>1st President of India</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name                     Term\n",
       "0           Shri Ram Nath Kovind  14th President of India\n",
       "1          Shri Pranab Mukherjee  13th President of India\n",
       "2   Smt Pratibha Devisingh Patil  12th President of India\n",
       "3         DR. A.P.J. Abdul Kalam  11th President of India\n",
       "4           Shri K. R. Narayanan  10th President of India\n",
       "5        Dr Shankar Dayal Sharma  9th  President of India\n",
       "6            Shri R Venkataraman   8th President of India\n",
       "7               Giani Zail Singh   7th President of India\n",
       "8      Shri Neelam Sanjiva Reddy   6th President of India\n",
       "9       Dr. Fakhruddin Ali Ahmed   5th President of India\n",
       "10  Shri Varahagiri Venkata Giri   4th President of India\n",
       "11              Dr. Zakir Husain   3rd President of India\n",
       "12  Dr. Sarvepalli Radhakrishnan   2nd President of India\n",
       "13           Dr. Rajendra Prasad   1st President of India"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sending a GET request to the URL\n",
    "response = requests.get(\"https://presidentofindia.nic.in/former-presidents\")\n",
    "#Parsing the content of HTML using BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "#Create an empty list\n",
    "frm_presidents = []\n",
    "#Find all the past presidents in the articles on the page\n",
    "president = soup.find_all('div',class_=\"desc-sec\")\n",
    "\n",
    "#looping through the contents and extract all the past presidents\n",
    "for president in soup.find_all('div',class_=\"desc-sec\"):\n",
    "    name = president.find(\"h3\").text.strip()\n",
    "    term = president.find(\"h5\").text.strip()\n",
    "    frm_presidents.append((name, term))\n",
    "\n",
    "#Creating a DataFrame from the extracted data\n",
    "df = pd.DataFrame(frm_presidents, columns=[\"Name\", \"Term\"])\n",
    "\n",
    "#display result\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3- Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* i) Top 10 ODI teams in men’s cricket along with the records for matches, points and \n",
    "rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_name</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India</td>\n",
       "      <td>44</td>\n",
       "      <td>5,085</td>\n",
       "      <td>116               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>27</td>\n",
       "      <td>3,102</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>31</td>\n",
       "      <td>3,464</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>24</td>\n",
       "      <td>2,551</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>England</td>\n",
       "      <td>29</td>\n",
       "      <td>3,057</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>33</td>\n",
       "      <td>3,397</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>38</td>\n",
       "      <td>3,512</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>35</td>\n",
       "      <td>3,209</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>21</td>\n",
       "      <td>1,687</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>38</td>\n",
       "      <td>2,582</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team_name Matches Points  \\\n",
       "0         India      44  5,085   \n",
       "1      Pakistan      27  3,102   \n",
       "2     Australia      31  3,464   \n",
       "3  South Africa      24  2,551   \n",
       "4       England      29  3,057   \n",
       "5   New Zealand      33  3,397   \n",
       "6     Sri Lanka      38  3,512   \n",
       "7    Bangladesh      35  3,209   \n",
       "8   Afghanistan      21  1,687   \n",
       "9   West Indies      38  2,582   \n",
       "\n",
       "                                             Ratings  \n",
       "0                              116               ...  \n",
       "1                                                115  \n",
       "2                                                112  \n",
       "3                                                106  \n",
       "4                                                105  \n",
       "5                                                103  \n",
       "6                                                 92  \n",
       "7                                                 92  \n",
       "8                                                 80  \n",
       "9                                                 68  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "page5 = requests.get(url)\n",
    "# see content in page5\n",
    "soup5 = BeautifulSoup(page5.content)\n",
    "#scrape team names\n",
    "team = soup5.find_all(\"span\",class_='u-hide-phablet')\n",
    "team_name = []\n",
    "for i in team:\n",
    "    team_name.append(i.text)\n",
    "matches = [] #empty list\n",
    "points = [] #empty list\n",
    "ratings = [] #empty list\n",
    "new_list = [] #empty list\n",
    "\n",
    "for i in soup5.find_all(\"td\",class_='rankings-block__banner--matches'): # first place team number of matches\n",
    "    matches.append(i.text)\n",
    "for i in soup5.find_all(\"td\",class_='rankings-block__banner--points'):# first place team points\n",
    "    points.append(i.text)\n",
    "for i in soup5.find_all(\"td\",class_='rankings-block__banner--rating u-text-right'):# first place team ratings\n",
    "    ratings.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell u-center-text'):# other teams number of matches and points\n",
    "    new_list.append(i.text)\n",
    "for i in range(0,len(new_list)-1,2):\n",
    "    matches.append(new_list[i]) # other teams matches\n",
    "    points.append(new_list[i+1]) # other teams points\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell u-text-right rating'):# other teams ratings\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "# Make data frame of top 10 ICC teams\n",
    "icc=pd.DataFrame({})\n",
    "icc['Team_name']=team_name[:10]\n",
    "icc['Matches']=matches[:10]\n",
    "icc['Points']=points[:10]\n",
    "icc['Ratings']=ratings[:10]\n",
    "icc    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ii) Top 10 ODI Batsmen in men along with the records of their team and rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shubman Gill</td>\n",
       "      <td>IND</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Tector</td>\n",
       "      <td>IRE</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Heinrich Klaasen</td>\n",
       "      <td>SA</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Player                     Team Rating\n",
       "0             Babar Azam  PAK                        857\n",
       "1           Shubman Gill                      IND    847\n",
       "2  Rassie van der Dussen                       SA    743\n",
       "3           Harry Tector                      IRE    729\n",
       "4            Imam-ul-Haq                      PAK    728\n",
       "5           David Warner                      AUS    720\n",
       "6        Quinton de Kock                       SA    714\n",
       "7       Heinrich Klaasen                       SA    698\n",
       "8            Virat Kohli                      IND    694\n",
       "9           Fakhar Zaman                      PAK    692"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n",
    "page6 = requests.get(url)\n",
    "# see content in page6\n",
    "soup6 = BeautifulSoup(page6.content)\n",
    "players = [] #empty list\n",
    "team_name = [] #empty list\n",
    "rating = [] #empty list\n",
    "\n",
    "for i in soup6.find_all(\"div\",class_='rankings-block__banner--name-large'): # first place player name\n",
    "    players.append(i.text)\n",
    "for i in soup6.find_all(\"div\",class_='rankings-block__banner--nationality'): # first place player team name\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup6.find_all(\"div\",class_='rankings-block__banner--rating'): # first place player rating\n",
    "    rating.append(i.text)\n",
    "for i in soup6.find_all(\"td\",class_='table-body__cell rankings-table__name name'):# players name\n",
    "    for j in i.find_all('a'):\n",
    "        players.append(j.text)\n",
    "for i in soup6.find_all(\"span\",class_='table-body__logo-text'): # players team name\n",
    "    team_name.append(i.text)\n",
    "for i in soup6.find_all(\"td\",class_='table-body__cell rating'): # players rating\n",
    "    rating.append(i.text)\n",
    "# Make data frame of top 10 ICC Batsmen\n",
    "Batsmen=pd.DataFrame({})\n",
    "Batsmen['Player']=players[:10]\n",
    "Batsmen['Team']=team_name[:10]\n",
    "Batsmen['Rating']=rating[:10]\n",
    "Batsmen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* iii) Top 10 ODI bowlers along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mohammed Siraj</td>\n",
       "      <td>IND</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adam Zampa</td>\n",
       "      <td>AUS</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kuldeep Yadav</td>\n",
       "      <td>IND</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player                     Team Rating\n",
       "0    Mohammed Siraj  IND                        680\n",
       "1    Josh Hazlewood                      AUS    669\n",
       "2  Mujeeb Ur Rahman                      AFG    657\n",
       "3       Rashid Khan                      AFG    655\n",
       "4       Trent Boult                       NZ    654\n",
       "5    Mitchell Starc                      AUS    639\n",
       "6        Adam Zampa                      AUS    637\n",
       "7    Shaheen Afridi                      PAK    632\n",
       "8        Matt Henry                       NZ    626\n",
       "9     Kuldeep Yadav                      IND    625"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "page7 = requests.get(url)\n",
    "\n",
    "# see content in page7\n",
    "soup7 = BeautifulSoup(page7.content)\n",
    "\n",
    "players = [] #empty list\n",
    "team_name = [] #empty list  \n",
    "rating = [] #empty list \n",
    "\n",
    "for i in soup7.find_all(\"div\",class_='rankings-block__banner--name-large'): # first place player name\n",
    "    players.append(i.text)\n",
    "for i in soup7.find_all(\"div\",class_='rankings-block__banner--nationality'): # first place player team name\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup7.find_all(\"div\",class_='rankings-block__banner--rating'): # first place player rating\n",
    "    rating.append(i.text)\n",
    "for i in soup7.find_all(\"td\",class_='table-body__cell rankings-table__name name'):# players name\n",
    "    for j in i.find_all('a'):\n",
    "        players.append(j.text)\n",
    "for i in soup7.find_all(\"span\",class_='table-body__logo-text'): # players team name\n",
    "    team_name.append(i.text)\n",
    "for i in soup7.find_all(\"td\",class_='table-body__cell rating'): # players rating\n",
    "    rating.append(i.text)\n",
    "# Make data frame of top 10 ICC bowlers\n",
    "bowlers=pd.DataFrame({})\n",
    "bowlers['Player']=players[:10]\n",
    "bowlers['Team']=team_name[:10]\n",
    "bowlers['Rating']=rating[:10]\n",
    "bowlers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question 4 - Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* i) Top 10 ODI teams in women’s cricket along with the records for matches, points \n",
    "and rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_name</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>26</td>\n",
       "      <td>4,290</td>\n",
       "      <td>165               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>33</td>\n",
       "      <td>4,145</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>30</td>\n",
       "      <td>3,533</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>30</td>\n",
       "      <td>3,039</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>29</td>\n",
       "      <td>2,755</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>29</td>\n",
       "      <td>2,743</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>17</td>\n",
       "      <td>1,284</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>13</td>\n",
       "      <td>883</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>14</td>\n",
       "      <td>936</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>30</td>\n",
       "      <td>1,933</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team_name Matches Points  \\\n",
       "0     Australia      26  4,290   \n",
       "1       England      33  4,145   \n",
       "2  South Africa      30  3,533   \n",
       "3         India      30  3,039   \n",
       "4   New Zealand      29  2,755   \n",
       "5   West Indies      29  2,743   \n",
       "6    Bangladesh      17  1,284   \n",
       "7      Thailand      13    883   \n",
       "8     Sri Lanka      14    936   \n",
       "9      Pakistan      30  1,933   \n",
       "\n",
       "                                             Ratings  \n",
       "0                              165               ...  \n",
       "1                                                126  \n",
       "2                                                118  \n",
       "3                                                101  \n",
       "4                                                 95  \n",
       "5                                                 95  \n",
       "6                                                 76  \n",
       "7                                                 68  \n",
       "8                                                 67  \n",
       "9                                                 64  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "page8 = requests.get(url)\n",
    "#see content in page8\n",
    "soup8 = BeautifulSoup(page8.content)\n",
    "#scrape team names\n",
    "womens_team = soup8.find_all(\"span\",class_='u-hide-phablet')\n",
    "womens_team_name = []\n",
    "for i in womens_team:\n",
    "    womens_team_name.append(i.text)\n",
    "womens_matches = [] #empty list\n",
    "womens_points = [] #empty list\n",
    "womens_ratings = [] #empty list\n",
    "womens_new_list = [] #empty list\n",
    "for i in soup8.find_all(\"td\",class_='rankings-block__banner--matches'): # first place team number of matches\n",
    "    womens_matches.append(i.text)\n",
    "for i in soup8.find_all(\"td\",class_='rankings-block__banner--points'):# first place team points\n",
    "    womens_points.append(i.text)\n",
    "for i in soup8.find_all(\"td\",class_='rankings-block__banner--rating u-text-right'):# first place team ratings\n",
    "    womens_ratings.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup8.find_all(\"td\",class_='table-body__cell u-center-text'):# other teams number of matches and points\n",
    "    womens_new_list.append(i.text)\n",
    "for i in range(0,len(womens_new_list)-1,2):\n",
    "    womens_matches.append(womens_new_list[i]) # other teams matches\n",
    "    womens_points.append(womens_new_list[i+1]) # other teams points\n",
    "for i in soup8.find_all(\"td\",class_='table-body__cell u-text-right rating'):# other teams number of matches and ratings\n",
    "    womens_ratings.append(i.text)\n",
    "# Make data frame of top 10 ICC teams\n",
    "womens_icc=pd.DataFrame({})\n",
    "womens_icc['Team_name']=womens_team_name[:10]\n",
    "womens_icc['Matches']=womens_matches[:10]\n",
    "womens_icc['Points']=womens_points[:10]\n",
    "womens_icc['Ratings']=womens_ratings[:10]\n",
    "womens_icc    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ii) Top 10 women’s ODI players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natalie Sciver-Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Player                     Team Rating\n",
       "0  Natalie Sciver-Brunt  ENG                        807\n",
       "1           Beth Mooney                      AUS    751\n",
       "2   Chamari Athapaththu                       SL    736\n",
       "3       Smriti Mandhana                      IND    708\n",
       "4          Alyssa Healy                      AUS    702\n",
       "5       Laura Wolvaardt                       SA    696\n",
       "6      Harmanpreet Kaur                      IND    694\n",
       "7          Ellyse Perry                      AUS    686\n",
       "8           Meg Lanning                      AUS    682\n",
       "9       Stafanie Taylor                       WI    618"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "page9 = requests.get(url)\n",
    "# see content in page9\n",
    "soup9 = BeautifulSoup(page9.content)\n",
    "players = [] #empty list\n",
    "team_name = [] #empty list\n",
    "rating = [] #empty list\n",
    "\n",
    "for i in soup9.find_all(\"div\",class_='rankings-block__banner--name-large'): # first place player name\n",
    "    players.append(i.text)\n",
    "for i in soup9.find_all(\"div\",class_='rankings-block__banner--nationality'): # first place player team name\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup9.find_all(\"div\",class_='rankings-block__banner--rating'): # first place player rating\n",
    "    rating.append(i.text)\n",
    "for i in soup9.find_all(\"td\",class_='table-body__cell rankings-table__name name'):# players name\n",
    "    for j in i.find_all('a'):\n",
    "        players.append(j.text)\n",
    "for i in soup9.find_all(\"span\",class_='table-body__logo-text'): # players team name\n",
    "    team_name.append(i.text)\n",
    "for i in soup9.find_all(\"td\",class_='table-body__cell rating'): # players rating\n",
    "    rating.append(i.text)\n",
    "# Make data frame of top 10 Women's ODI Batting Rankings\n",
    "top_players=pd.DataFrame({})\n",
    "top_players['Player']=players[:10]\n",
    "top_players['Team']=team_name[:10]\n",
    "top_players['Rating']=rating[:10]\n",
    "top_players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* iii)Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver-Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nida Dar</td>\n",
       "      <td>PAK</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Player                     Team Rating\n",
       "0      Ashleigh Gardner  AUS                        389\n",
       "1       Hayley Matthews                       WI    382\n",
       "2        Marizanne Kapp                       SA    361\n",
       "3  Natalie Sciver-Brunt                      ENG    360\n",
       "4          Ellyse Perry                      AUS    329\n",
       "5           Amelia Kerr                       NZ    324\n",
       "6         Deepti Sharma                      IND    312\n",
       "7         Jess Jonassen                      AUS    241\n",
       "8              Nida Dar                      PAK    224\n",
       "9         Sophie Devine                       NZ    223"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n",
    "page10 = requests.get(url)\n",
    "\n",
    "# see content in page10\n",
    "soup10 = BeautifulSoup(page10.content)\n",
    "\n",
    "players = [] #empty list\n",
    "team_name = [] #empty list  \n",
    "rating = [] #empty list \n",
    "\n",
    "for i in soup10.find_all(\"div\",class_='rankings-block__banner--name-large'): # first place player name\n",
    "    players.append(i.text)\n",
    "for i in soup10.find_all(\"div\",class_='rankings-block__banner--nationality'): # first place player team name\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup10.find_all(\"div\",class_='rankings-block__banner--rating'): # first place player rating\n",
    "    rating.append(i.text)\n",
    "for i in soup10.find_all(\"td\",class_='table-body__cell rankings-table__name name'):# players name\n",
    "    for j in i.find_all('a'):\n",
    "        players.append(j.text)\n",
    "for i in soup10.find_all(\"span\",class_='table-body__logo-text'): # players team name\n",
    "    team_name.append(i.text)\n",
    "for i in soup10.find_all(\"td\",class_='table-body__cell rating'): # players rating\n",
    "    rating.append(i.text)\n",
    "# Make data frame of top 10 ICC Women's ODI All-Rounder Rankings\n",
    "all_rounder=pd.DataFrame({})\n",
    "all_rounder['Player']=players[:10]\n",
    "all_rounder['Team']=team_name[:10]\n",
    "all_rounder['Rating']=rating[:10]\n",
    "all_rounder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-5 Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :\n",
    "i) Headline\n",
    "ii) Time\n",
    "iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.cnbc.com/world/?region=world\"\n",
    "page7 = requests.get(url)\n",
    "# see content in page7\n",
    "soup7 = BeautifulSoup(page7.content)\n",
    "\n",
    "\n",
    "# creaing empty lists \n",
    "time = []\n",
    "headline = []\n",
    "newsLink = []\n",
    "\n",
    "#Iterating over all the news\n",
    "for i in soup7.find_all(\"div\",class_=\"LatestNews-container\"):\n",
    "     headline.append(i.find(\"a\",class_=\"LatestNews-headline\").text)  \n",
    "        \n",
    "for i in soup7.find_all(\"div\",class_=\"LatestNews-container\"):\n",
    "     time.append(i.find(\"time\").text)   \n",
    "        \n",
    "for i in soup7.find_all(\"div\",class_=\"LatestNews-container\"):\n",
    "     newsLink.append(i.find(\"a\",class_=\"LatestNews-headline\").get(\"href\"))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "      <th>News Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beyoncé's Renaissance World Tour in talks with...</td>\n",
       "      <td>16 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/30/beyoncs-renais...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>These are the top 4 Club stocks — and the bott...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/30/these-are-the-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple will issue a software update to address ...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/30/apple-will-iss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55-year-old whose side hustle brought in $20K ...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/30/55-year-old-wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can the MIND diet lower your risk of dementia?...</td>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/30/mind-diet-can-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Government shutdown updates: Biden signs 45-da...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/30/government-shu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This couple built a $40 million ice cream comp...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/30/ample-hills-co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FAFSA won't open Oct. 1 this year—here's when ...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/30/fafsa-student-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3 things that will impact stocks going into th...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/30/3-things-that-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How much money you need to make to be in the t...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/30/how-much-money...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Meta has Apple to thank for giving its annual ...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/30/meta-has-apple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Why this 53-year-old American retiree, family ...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/30/american-retir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Buy stocks like this homebuilder as interest r...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/30/buy-these-stoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Oil prices and the dollar surged in the third ...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/30/quarterly-inve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Danger, 'pothole' ahead: Economic growth slowi...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/30/danger-pothole...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Stocks enter October in a 2-month correction</td>\n",
       "      <td>23 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/30/stocks-enter-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>83% of Gen Z are job hoppers. How to handle ol...</td>\n",
       "      <td>23 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/09/30/gen-z-workers-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cramer says don't make any moves right before ...</td>\n",
       "      <td>September 29, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/09/29/cramer-says-do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cramer's Lightning Round: Caterpillar is a buy</td>\n",
       "      <td>September 29, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/09/29/cramers-lightn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Jim Cramer's week ahead: Focus on September jo...</td>\n",
       "      <td>September 29, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/09/29/cramers-week-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>These are the 10 most neighborly cities in the...</td>\n",
       "      <td>September 29, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/09/29/neighborly-cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Expert: What a government shut down could mean...</td>\n",
       "      <td>September 29, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/09/29/what-a-governm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Federal judge declines to block Medicare drug ...</td>\n",
       "      <td>September 29, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/09/29/medicare-price...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Nike shares pop after mixed first-quarter resu...</td>\n",
       "      <td>September 29, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/09/29/nike-shares-po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Bill Ackman’s 'SPARC' gets OK from the SEC and...</td>\n",
       "      <td>September 29, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/09/29/bill-ackmans-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JetBlue raises flight attendant pay, union agr...</td>\n",
       "      <td>September 29, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/09/29/jetblue-raises...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Biden’s pro-competition agenda tested as net n...</td>\n",
       "      <td>September 29, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/09/29/bidens-pro-com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>55-year-old quit his job for his side hustle—h...</td>\n",
       "      <td>September 29, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/09/29/how-55-year-ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Mark Cuban wants to give you personalized advi...</td>\n",
       "      <td>September 29, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/09/29/mark-cuban-cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>First co-defendant in Trump Georgia election c...</td>\n",
       "      <td>September 29, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/09/29/first-co-defen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline                Time  \\\n",
       "0   Beyoncé's Renaissance World Tour in talks with...        16 Hours Ago   \n",
       "1   These are the top 4 Club stocks — and the bott...        17 Hours Ago   \n",
       "2   Apple will issue a software update to address ...        17 Hours Ago   \n",
       "3   55-year-old whose side hustle brought in $20K ...        19 Hours Ago   \n",
       "4   Can the MIND diet lower your risk of dementia?...        20 Hours Ago   \n",
       "5   Government shutdown updates: Biden signs 45-da...        21 Hours Ago   \n",
       "6   This couple built a $40 million ice cream comp...        21 Hours Ago   \n",
       "7   FAFSA won't open Oct. 1 this year—here's when ...        21 Hours Ago   \n",
       "8   3 things that will impact stocks going into th...        21 Hours Ago   \n",
       "9   How much money you need to make to be in the t...        22 Hours Ago   \n",
       "10  Meta has Apple to thank for giving its annual ...        22 Hours Ago   \n",
       "11  Why this 53-year-old American retiree, family ...        22 Hours Ago   \n",
       "12  Buy stocks like this homebuilder as interest r...        22 Hours Ago   \n",
       "13  Oil prices and the dollar surged in the third ...        22 Hours Ago   \n",
       "14  Danger, 'pothole' ahead: Economic growth slowi...        22 Hours Ago   \n",
       "15       Stocks enter October in a 2-month correction        23 Hours Ago   \n",
       "16  83% of Gen Z are job hoppers. How to handle ol...        23 Hours Ago   \n",
       "17  Cramer says don't make any moves right before ...  September 29, 2023   \n",
       "18     Cramer's Lightning Round: Caterpillar is a buy  September 29, 2023   \n",
       "19  Jim Cramer's week ahead: Focus on September jo...  September 29, 2023   \n",
       "20  These are the 10 most neighborly cities in the...  September 29, 2023   \n",
       "21  Expert: What a government shut down could mean...  September 29, 2023   \n",
       "22  Federal judge declines to block Medicare drug ...  September 29, 2023   \n",
       "23  Nike shares pop after mixed first-quarter resu...  September 29, 2023   \n",
       "24  Bill Ackman’s 'SPARC' gets OK from the SEC and...  September 29, 2023   \n",
       "25  JetBlue raises flight attendant pay, union agr...  September 29, 2023   \n",
       "26  Biden’s pro-competition agenda tested as net n...  September 29, 2023   \n",
       "27  55-year-old quit his job for his side hustle—h...  September 29, 2023   \n",
       "28  Mark Cuban wants to give you personalized advi...  September 29, 2023   \n",
       "29  First co-defendant in Trump Georgia election c...  September 29, 2023   \n",
       "\n",
       "                                            News Link  \n",
       "0   https://www.cnbc.com/2023/09/30/beyoncs-renais...  \n",
       "1   https://www.cnbc.com/2023/09/30/these-are-the-...  \n",
       "2   https://www.cnbc.com/2023/09/30/apple-will-iss...  \n",
       "3   https://www.cnbc.com/2023/09/30/55-year-old-wi...  \n",
       "4   https://www.cnbc.com/2023/09/30/mind-diet-can-...  \n",
       "5   https://www.cnbc.com/2023/09/30/government-shu...  \n",
       "6   https://www.cnbc.com/2023/09/30/ample-hills-co...  \n",
       "7   https://www.cnbc.com/2023/09/30/fafsa-student-...  \n",
       "8   https://www.cnbc.com/2023/09/30/3-things-that-...  \n",
       "9   https://www.cnbc.com/2023/09/30/how-much-money...  \n",
       "10  https://www.cnbc.com/2023/09/30/meta-has-apple...  \n",
       "11  https://www.cnbc.com/2023/09/30/american-retir...  \n",
       "12  https://www.cnbc.com/2023/09/30/buy-these-stoc...  \n",
       "13  https://www.cnbc.com/2023/09/30/quarterly-inve...  \n",
       "14  https://www.cnbc.com/2023/09/30/danger-pothole...  \n",
       "15  https://www.cnbc.com/2023/09/30/stocks-enter-o...  \n",
       "16  https://www.cnbc.com/2023/09/30/gen-z-workers-...  \n",
       "17  https://www.cnbc.com/2023/09/29/cramer-says-do...  \n",
       "18  https://www.cnbc.com/2023/09/29/cramers-lightn...  \n",
       "19  https://www.cnbc.com/2023/09/29/cramers-week-a...  \n",
       "20  https://www.cnbc.com/2023/09/29/neighborly-cit...  \n",
       "21  https://www.cnbc.com/2023/09/29/what-a-governm...  \n",
       "22  https://www.cnbc.com/2023/09/29/medicare-price...  \n",
       "23  https://www.cnbc.com/2023/09/29/nike-shares-po...  \n",
       "24  https://www.cnbc.com/2023/09/29/bill-ackmans-s...  \n",
       "25  https://www.cnbc.com/2023/09/29/jetblue-raises...  \n",
       "26  https://www.cnbc.com/2023/09/29/bidens-pro-com...  \n",
       "27  https://www.cnbc.com/2023/09/29/how-55-year-ol...  \n",
       "28  https://www.cnbc.com/2023/09/29/mark-cuban-cou...  \n",
       "29  https://www.cnbc.com/2023/09/29/first-co-defen...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Dataset\n",
    "data = list(zip(headline,time,newsLink))                                           #zipping data\n",
    "df = pd.DataFrame(data,columns=[\"Headline\",\"Time\",\"News Link\"])   \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q- 6 Write a python program to scrape the details of most downloaded articles from AI in last 90 days. \n",
    "https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "Scrape below mentioned details :\n",
    "i) Paper Title \n",
    "ii) Authors\n",
    "iii) Published Date \n",
    "iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>David Silver, Satinder Singh, Doina Precup, Ri...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Tim Miller</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Margaret A. Boden</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Guni Sharon, Roni Stern, Ariel Felner, Nathan ...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Knowledge graphs as tools for explainable mach...</td>\n",
       "      <td>Ilaria Tiddi, Stefan Schlobach</td>\n",
       "      <td>January 2022</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Henry Prakken, Giovanni Sartor</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Richard S. Sutton, Doina Precup, Satinder Singh</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Kjersti Aas, Martin Jullum, Anders Løland</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Wenhan Luo, Junliang Xing and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Saurabh Arora, Prashant Doshi</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>Jasper van der Waa, Elisabeth Nieuwburg, Anita...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Explainable AI tools for legal reasoning about...</td>\n",
       "      <td>Joe Collenette, Katie Atkinson, Trevor Bench-C...</td>\n",
       "      <td>April 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hard choices in artificial intelligence</td>\n",
       "      <td>Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz</td>\n",
       "      <td>November 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Assessing the communication gap between AI mod...</td>\n",
       "      <td>Oskar Wysocki, Jessica Katharine Davies and 5 ...</td>\n",
       "      <td>March 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Nolan Bard, Jakob N. Foerster and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Ron Kohavi, George H. John</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Séverin Lemaignan, Mathieu Warnier and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The multifaceted impact of Ada Lovelace in the...</td>\n",
       "      <td>Luigia Carlucci Aiello</td>\n",
       "      <td>June 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Robot ethics: Mapping the issues for a mechani...</td>\n",
       "      <td>Patrick Lin, Keith Abney, George Bekey</td>\n",
       "      <td>April 2011</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Reward (Mis)design for autonomous driving</td>\n",
       "      <td>W. Bradley Knox, Alessandro Allievi and 3 more</td>\n",
       "      <td>March 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Planning and acting in partially observable st...</td>\n",
       "      <td>Leslie Pack Kaelbling, Michael L. Littman, Ant...</td>\n",
       "      <td>May 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What do we want from Explainable Artificial In...</td>\n",
       "      <td>Markus Langer, Daniel Oster and 6 more</td>\n",
       "      <td>July 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper Title  \\\n",
       "0                                    Reward is enough   \n",
       "1   Explanation in artificial intelligence: Insigh...   \n",
       "2              Creativity and artificial intelligence   \n",
       "3   Conflict-based search for optimal multi-agent ...   \n",
       "4   Knowledge graphs as tools for explainable mach...   \n",
       "5   Law and logic: A review from an argumentation ...   \n",
       "6   Between MDPs and semi-MDPs: A framework for te...   \n",
       "7   Explaining individual predictions when feature...   \n",
       "8       Multiple object tracking: A literature review   \n",
       "9   A survey of inverse reinforcement learning: Ch...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11  Explainable AI tools for legal reasoning about...   \n",
       "12            Hard choices in artificial intelligence   \n",
       "13  Assessing the communication gap between AI mod...   \n",
       "14  Explaining black-box classifiers using post-ho...   \n",
       "15  The Hanabi challenge: A new frontier for AI re...   \n",
       "16              Wrappers for feature subset selection   \n",
       "17  Artificial cognition for social human–robot in...   \n",
       "18  A review of possible effects of cognitive bias...   \n",
       "19  The multifaceted impact of Ada Lovelace in the...   \n",
       "20  Robot ethics: Mapping the issues for a mechani...   \n",
       "21          Reward (Mis)design for autonomous driving   \n",
       "22  Planning and acting in partially observable st...   \n",
       "23  What do we want from Explainable Artificial In...   \n",
       "\n",
       "                                              Authors  Published Date  \\\n",
       "0   David Silver, Satinder Singh, Doina Precup, Ri...    October 2021   \n",
       "1                                          Tim Miller   February 2019   \n",
       "2                                   Margaret A. Boden     August 1998   \n",
       "3   Guni Sharon, Roni Stern, Ariel Felner, Nathan ...   February 2015   \n",
       "4                      Ilaria Tiddi, Stefan Schlobach    January 2022   \n",
       "5                      Henry Prakken, Giovanni Sartor    October 2015   \n",
       "6     Richard S. Sutton, Doina Precup, Satinder Singh     August 1999   \n",
       "7           Kjersti Aas, Martin Jullum, Anders Løland  September 2021   \n",
       "8                Wenhan Luo, Junliang Xing and 4 more      April 2021   \n",
       "9                       Saurabh Arora, Prashant Doshi     August 2021   \n",
       "10  Jasper van der Waa, Elisabeth Nieuwburg, Anita...   February 2021   \n",
       "11  Joe Collenette, Katie Atkinson, Trevor Bench-C...      April 2023   \n",
       "12   Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz   November 2021   \n",
       "13  Oskar Wysocki, Jessica Katharine Davies and 5 ...      March 2023   \n",
       "14  Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...        May 2021   \n",
       "15          Nolan Bard, Jakob N. Foerster and 13 more      March 2020   \n",
       "16                         Ron Kohavi, George H. John   December 1997   \n",
       "17      Séverin Lemaignan, Mathieu Warnier and 3 more       June 2017   \n",
       "18    Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz       June 2021   \n",
       "19                             Luigia Carlucci Aiello       June 2016   \n",
       "20             Patrick Lin, Keith Abney, George Bekey      April 2011   \n",
       "21     W. Bradley Knox, Alessandro Allievi and 3 more      March 2023   \n",
       "22  Leslie Pack Kaelbling, Michael L. Littman, Ant...        May 1998   \n",
       "23             Markus Langer, Daniel Oster and 6 more       July 2021   \n",
       "\n",
       "                                            Paper URL  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Send a GET request to the URL\n",
    "response = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "\n",
    "#Parsing the content of HTML using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "#Finding all news articles on the web page\n",
    "article_items = soup.find_all(\"li\", class_=\"sc-9zxyh7-1 sc-9zxyh7-2 kOEIEO hvoVxs\")\n",
    "\n",
    "#Creating empty Lists to store extracted data\n",
    "paper_titles = []\n",
    "authors_list = []\n",
    "published_dates = []\n",
    "paper_urls = []\n",
    "\n",
    "#Iterating through the article content to extract article details\n",
    "for item in article_items:\n",
    "    # Extracting title of the article\n",
    "    title = item.find(\"h2\", class_=\"sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg\").get_text(strip=True)\n",
    "    paper_titles.append(title)\n",
    "    \n",
    "    # Extracting the authors\n",
    "    authors = item.find(\"span\",{'class': \"sc-1w3fpd7-0 dnCnAO\"}).get_text(strip=True)\n",
    "    authors_list.append(authors)\n",
    "    \n",
    "    # Extracting the published date\n",
    "    published_date = item.find(\"span\", class_=\"sc-1thf9ly-2 dvggWt\").get_text(strip=True)\n",
    "    published_dates.append(published_date)\n",
    "    \n",
    "    # Extracting the paper URL\n",
    "    paper_url = item.find(\"a\", class_=\"sc-5smygv-0 fIXTHm\")[\"href\"]\n",
    "    paper_urls.append(paper_url)\n",
    "\n",
    "#Creating a dictionary from the extracted data\n",
    "data = {\n",
    "    \"Paper Title\": paper_titles,\n",
    "    \"Authors\": authors_list,\n",
    "    \"Published Date\": published_dates,\n",
    "    \"Paper URL\": paper_urls\n",
    "}\n",
    "#Creating a DataFrame from the dictionar\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q7- Write a python program to scrape mentioned details from ‘https://www.dineout.co.in/delhi-restaurants/buffetspecial’ :\n",
    "i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send get request to the webpage server to get the source code of the page\n",
    "page = requests.get(\"https://www.dineout.co.in/delhi-restaurants/buffet-special\")\n",
    "# page content\n",
    "soup=BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "for i in soup.find_all(\"div\", class_=\"restnt-info cursor\"):\n",
    "    name.append(i.text) \n",
    "location=[]\n",
    "for i in soup.find_all(\"div\", class_=\"restnt-loc ellipsis\"):\n",
    "    location.append(i.text)\n",
    "\n",
    "price = []\n",
    "cuisine = []\n",
    "for i in soup.find_all(\"span\", class_=\"double-line-ellipsis\"):\n",
    "    price.append(i.text.split('|')[0])\n",
    "    cuisine.append(i.text.split('|')[1])\n",
    "\n",
    "rating=[]\n",
    "for i in soup.find_all(\"div\", class_=\"restnt-rating rating-3\"):\n",
    "    rating.append(i.text)\n",
    "for i in soup.find_all(\"div\", class_=\"restnt-rating rating-4\"):\n",
    "    rating.append(i.text)\n",
    "\n",
    "images = []\n",
    "for i in soup.find_all(\"img\", class_=\"no-img\"):\n",
    "    images.append(i['data-src'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9 9 9 9 9\n"
     ]
    }
   ],
   "source": [
    "print(len(name), len(location), len(price), len(cuisine), len(rating), len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Price</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Rating</th>\n",
       "      <th>IMAGES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle BarbequeConnaught Place, Central Delhi</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>₹ 2,000 for 2 (approx)</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cafe KnoshThe Leela Ambience Convention Hotel,...</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>₹ 3,000 for 2 (approx)</td>\n",
       "      <td>Italian, Continental</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle's BarbequePacific Mall,Tagore Garden, W...</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>₹ 2,000 for 2 (approx)</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India GrillHilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>₹ 2,400 for 2 (approx)</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque CompanyGardens Galleria,Sector 38...</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>₹ 1,700 for 2 (approx)</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>₹ 1,800 for 2 (approx)</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Monarch - Bar Be Que VillageIndirapuram Ha...</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>₹ 1,900 for 2 (approx)</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indian Grill RoomSuncity Business Tower,Golf C...</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>₹ 2,200 for 2 (approx)</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Barbeque TimesM2K Corporate Park,Sector 51...</td>\n",
       "      <td>M2K Corporate Park,Sector 51, Gurgaon</td>\n",
       "      <td>₹ 1,500 for 2 (approx)</td>\n",
       "      <td>North Indian, Continental, Chinese, South Indian</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Restaurant Name  \\\n",
       "0      Castle BarbequeConnaught Place, Central Delhi   \n",
       "1  Cafe KnoshThe Leela Ambience Convention Hotel,...   \n",
       "2  Castle's BarbequePacific Mall,Tagore Garden, W...   \n",
       "3    India GrillHilton Garden Inn,Saket, South Delhi   \n",
       "4  The Barbeque CompanyGardens Galleria,Sector 38...   \n",
       "5  Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...   \n",
       "6  The Monarch - Bar Be Que VillageIndirapuram Ha...   \n",
       "7  Indian Grill RoomSuncity Business Tower,Golf C...   \n",
       "8  The Barbeque TimesM2K Corporate Park,Sector 51...   \n",
       "\n",
       "                                            Location                    Price  \\\n",
       "0                     Connaught Place, Central Delhi  ₹ 2,000 for 2 (approx)    \n",
       "1  The Leela Ambience Convention Hotel,Shahdara, ...  ₹ 3,000 for 2 (approx)    \n",
       "2             Pacific Mall,Tagore Garden, West Delhi  ₹ 2,000 for 2 (approx)    \n",
       "3               Hilton Garden Inn,Saket, South Delhi  ₹ 2,400 for 2 (approx)    \n",
       "4                 Gardens Galleria,Sector 38A, Noida  ₹ 1,700 for 2 (approx)    \n",
       "5     Taurus Sarovar Portico,Mahipalpur, South Delhi  ₹ 1,800 for 2 (approx)    \n",
       "6  Indirapuram Habitat Centre,Indirapuram, Ghaziabad  ₹ 1,900 for 2 (approx)    \n",
       "7   Suncity Business Tower,Golf Course Road, Gurgaon  ₹ 2,200 for 2 (approx)    \n",
       "8              M2K Corporate Park,Sector 51, Gurgaon  ₹ 1,500 for 2 (approx)    \n",
       "\n",
       "                                             Cuisine Rating  \\\n",
       "0                              Chinese, North Indian      4   \n",
       "1                               Italian, Continental    4.3   \n",
       "2                              Chinese, North Indian    3.9   \n",
       "3                              North Indian, Italian    3.9   \n",
       "4                              North Indian, Chinese    3.9   \n",
       "5                                       North Indian    3.7   \n",
       "6                                       North Indian    3.8   \n",
       "7                              North Indian, Mughlai    4.3   \n",
       "8   North Indian, Continental, Chinese, South Indian    4.1   \n",
       "\n",
       "                                              IMAGES  \n",
       "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data frame\n",
    "DineOut=pd.DataFrame({})\n",
    "DineOut['Restaurant Name']=name\n",
    "DineOut['Location']=location\n",
    "DineOut['Price']=price \n",
    "DineOut['Cuisine']=cuisine  \n",
    "DineOut['Rating']=rating  \n",
    "DineOut['IMAGES']=images\n",
    "DineOut"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
